{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e5b253-49da-49fa-bdfe-84f54928dfac",
   "metadata": {},
   "source": [
    "# 12. Getting chatty (dialog engines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8a823-b9de-4b26-913e-4a68468bd81e",
   "metadata": {},
   "source": [
    "###  12.2.1 A pattern-matching chatbot with AIML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba770f6-0c78-4f04-939c-0b36d9f28aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: AIML-Bot==0.0.3 in /opt/conda/lib/python3.10/site-packages (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install AIML-Bot==0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a2d7b5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'time' has no attribute 'clock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\" AIML Step 1\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m<category><pattern>HELLO ROSA </pattern><template>Hi Human!</template></category>\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m<category><pattern>HELLO TROLL </pattern><template>Good one, human.</template></category>\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m bot \u001b[38;5;241m=\u001b[39m \u001b[43maiml_bot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgreeting_step1.aiml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/aiml_bot/bot.py:79\u001b[0m, in \u001b[0;36mBot.__init__\u001b[0;34m(self, brain_file, learn, commands, verbose)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# set up the word substitutors (subbers):\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subbers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: WordSub(default_gender),\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m'\u001b[39m: WordSub(default_person),\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson2\u001b[39m\u001b[38;5;124m'\u001b[39m: WordSub(default_person2),\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m: WordSub(default_normal)\n\u001b[1;32m     77\u001b[0m }\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrain_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/aiml_bot/bot.py:95\u001b[0m, in \u001b[0;36mBot.bootstrap\u001b[0;34m(self, brain_file, learn, commands)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m\"\"\"Prepare a Bot object for use.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mIf a brainFile argument is provided, the Bot attempts to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mpassed to respond().\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m loaded_brain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m brain_file \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(brain_file):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_brain(brain_file)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'time' has no attribute 'clock'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# from nlpia.constants import DATA_PATH\n",
    "import aiml_bot\n",
    "\n",
    "DATA_PATH = \"../../data\"\n",
    "\n",
    "\"\"\" AIML Step 1\n",
    "<category><pattern>HELLO ROSA </pattern><template>Hi Human!</template></category>\n",
    "<category><pattern>HELLO TROLL </pattern><template>Good one, human.</template></category>\n",
    "\"\"\"\n",
    "bot = aiml_bot.Bot(learn=os.path.join(DATA_PATH, 'greeting_step1.aiml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036606c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Hello Rosa,\")\n",
    "# 'Hi there!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"hello **troll** !!!\")\n",
    "# 'Good one, human.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2cba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Helo Rosa\")\n",
    "# WARNING: No match found for input: Helo Rosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Hello Ro-sa)\n",
    "# WARNING: No match found for input: Hello Ro-sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff16b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AIML Patterns Step2: Synonyms \"\"\"\n",
    "bot.learn(os.path.join(DATA_PATH, 'greeting_step2.aiml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eab658",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Hey Rosa\")\n",
    "# 'Hi there!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Hi Rosa\")\n",
    "# 'Hi there!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Helo Rosa\")\n",
    "# 'Hi there!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"hello **troll** !!!\")\n",
    "# 'Good one, human.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AIML Patterns Step3: Random Responses and Lists \"\"\"\n",
    "bot.learn(os.path.join(DATA_PATH, 'greeting_step3.aiml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5489793",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Hey Rosa\")\n",
    "# 'Hello friend'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Hey Rosa\")\n",
    "# 'Hey you :)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.respond(\"Hey Rosa\")\n",
    "# 'Hi Human!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a8b23",
   "metadata": {},
   "source": [
    "### 12.4.2 Example retrieval-based chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17daed90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think we could import the old comments via r...</td>\n",
       "      <td>basically each xfree86 upload will NOT force u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not suggesting all - only the ones you mod...</td>\n",
       "      <td>oh? oops. __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon all __eou__ not entirely related to ...</td>\n",
       "      <td>we'll have a BOF about this __eou__ so you're ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting __eou__ grub-install worked with /...</td>\n",
       "      <td>i fully endorse this suggestion &lt;/quimby&gt; __eo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  i think we could import the old comments via r...   \n",
       "1  I'm not suggesting all - only the ones you mod...   \n",
       "2  afternoon all __eou__ not entirely related to ...   \n",
       "3  interesting __eou__ grub-install worked with /...   \n",
       "\n",
       "                                           Utterance  \n",
       "0  basically each xfree86 upload will NOT force u...  \n",
       "1                                  oh? oops. __eou__  \n",
       "2  we'll have a BOF about this __eou__ so you're ...  \n",
       "3  i fully endorse this suggestion </quimby> __eo...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nlpia.data.loaders import get_data\n",
    "\n",
    "# df = get_data('ubuntu_dialog')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../bigdata/ubuntu_dialog_1500k.csv.gz\", index_col=0)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3437dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_turns(s, splitter=re.compile('__eot__')):\n",
    "    \"\"\" Split a string on __eot__ markders (turns) \"\"\"\n",
    "    for utterance in splitter.split(s):\n",
    "        utterance = utterance.replace('__eou__', '\\n')\n",
    "        utterance = utterance.replace('__eot__', '')\n",
    "        if len(utterance.strip()):\n",
    "            yield utterance\n",
    "\n",
    "\n",
    "def preprocess_ubuntu_corpus(df):\n",
    "    \"\"\"Split all strings in df.Context and df.Utterance on __eot__ (turn) markers \"\"\"\n",
    "    statements = []\n",
    "    replies = []\n",
    "    for i, record in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        turns = list(split_turns(record.Context))\n",
    "        statement = turns[-1] if len(turns) else '\\n'  # <1>\n",
    "        statements.append(statement)\n",
    "        turns = list(split_turns(record.Utterance))\n",
    "        reply = turns[-1] if len(turns) else '\\n'\n",
    "        replies.append(reply)\n",
    "    df['statement'] = statements\n",
    "    df['reply'] = replies\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_ubuntu_dialog(df):\n",
    "    \"\"\" Print statements paired with replies, formatted for easy review \"\"\"\n",
    "    s = ''\n",
    "    for i, record in df.iterrows():\n",
    "        statement = list(split_turns(record.Context))[-1]  # <1>\n",
    "        reply = list(split_turns(record.Utterance))[-1]  # <2>\n",
    "        s += 'Statement: {}\\n'.format(statement)\n",
    "        s += 'Reply: {}\\n\\n'.format(reply)\n",
    "    return s\n",
    "    # <1> We need to use `list` to force iteration through the generator\n",
    "    # <2> The `[-1]` index retrievs the last \"turn\" in the sequence, discarding everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64e44b7-d157-476e-87dc-291f5ac0436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement:  I would prefer to avoid it at this stage.  this is something that has gone into XSF svn, I assume? \n",
      " \n",
      "Reply: basically each xfree86 upload will NOT force users to upgrade 100Mb of fonts for nothing \n",
      " no something i did in my spare time. \n",
      "\n",
      "\n",
      "Statement:  ok, it sounds like you're agreeing with me, then \n",
      " though rather than \"the ones we modify\", my idea is \"the ones we need to merge\" \n",
      " \n",
      "Reply: oh? oops. \n",
      "\n",
      "\n",
      "Statement:  should g2 in ubuntu do the magic dont-focus-window tricks? \n",
      " join the gang, get an x-series thinkpad \n",
      " sj has hung on my box, again. \n",
      " what is monday mornings discussion actually about? \n",
      " \n",
      "Reply: we'll have a BOF about this \n",
      " so you're coming tomorrow ? \n",
      "\n",
      "\n",
      "Statement:  i want it on in sarge too but nobody else agrees \n",
      " \n",
      "Reply: i fully endorse this suggestion </quimby> \n",
      " how did your reinstall go? \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_ubuntu_dialog(df.head(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6f581e-76df-4bbd-9af8-822034d5fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1499744/1499744 [01:44<00:00, 14357.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>statement</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think we could import the old comments via r...</td>\n",
       "      <td>basically each xfree86 upload will NOT force u...</td>\n",
       "      <td>I would prefer to avoid it at this stage.  th...</td>\n",
       "      <td>basically each xfree86 upload will NOT force u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not suggesting all - only the ones you mod...</td>\n",
       "      <td>oh? oops. __eou__</td>\n",
       "      <td>ok, it sounds like you're agreeing with me, t...</td>\n",
       "      <td>oh? oops. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon all __eou__ not entirely related to ...</td>\n",
       "      <td>we'll have a BOF about this __eou__ so you're ...</td>\n",
       "      <td>should g2 in ubuntu do the magic dont-focus-w...</td>\n",
       "      <td>we'll have a BOF about this \\n so you're comin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting __eou__ grub-install worked with /...</td>\n",
       "      <td>i fully endorse this suggestion &lt;/quimby&gt; __eo...</td>\n",
       "      <td>i want it on in sarge too but nobody else agr...</td>\n",
       "      <td>i fully endorse this suggestion &lt;/quimby&gt; \\n h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  i think we could import the old comments via r...   \n",
       "1  I'm not suggesting all - only the ones you mod...   \n",
       "2  afternoon all __eou__ not entirely related to ...   \n",
       "3  interesting __eou__ grub-install worked with /...   \n",
       "\n",
       "                                           Utterance  \\\n",
       "0  basically each xfree86 upload will NOT force u...   \n",
       "1                                  oh? oops. __eou__   \n",
       "2  we'll have a BOF about this __eou__ so you're ...   \n",
       "3  i fully endorse this suggestion </quimby> __eo...   \n",
       "\n",
       "                                           statement  \\\n",
       "0   I would prefer to avoid it at this stage.  th...   \n",
       "1   ok, it sounds like you're agreeing with me, t...   \n",
       "2   should g2 in ubuntu do the magic dont-focus-w...   \n",
       "3   i want it on in sarge too but nobody else agr...   \n",
       "\n",
       "                                               reply  \n",
       "0  basically each xfree86 upload will NOT force u...  \n",
       "1                                       oh? oops. \\n  \n",
       "2  we'll have a BOF about this \\n so you're comin...  \n",
       "3  i fully endorse this suggestion </quimby> \\n h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess_ubuntu_corpus(df)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a12e1a-84e2-44bb-811b-c38207c35b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>statement</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415808</td>\n",
       "      <td>Hi, can someone tell me how to install OTR (Of...</td>\n",
       "      <td>PriceChild: thanks a lot! __eou__</td>\n",
       "      <td>install the pidgin-otr package \\n</td>\n",
       "      <td>PriceChild: thanks a lot! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503946</td>\n",
       "      <td>﻿Jabar: do it in a terminal/shell: cat ~/.xses...</td>\n",
       "      <td>you're welcome __eou__</td>\n",
       "      <td>thanks \\n</td>\n",
       "      <td>you're welcome \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675140</td>\n",
       "      <td>I was currently running Windows 7, downloaded ...</td>\n",
       "      <td>Right.  You'll need to run your live-cd and go...</td>\n",
       "      <td>: That would be very nice due to the fact tha...</td>\n",
       "      <td>Right.  You'll need to run your live-cd and go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>605818</td>\n",
       "      <td>Alright, I'm having serious issues with the li...</td>\n",
       "      <td>I'm not in the directory! __eou__</td>\n",
       "      <td>: or cd out of devices the directory... that ...</td>\n",
       "      <td>I'm not in the directory! \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                            Context  \\\n",
       "0   415808  Hi, can someone tell me how to install OTR (Of...   \n",
       "1   503946  ﻿Jabar: do it in a terminal/shell: cat ~/.xses...   \n",
       "2  1675140  I was currently running Windows 7, downloaded ...   \n",
       "3   605818  Alright, I'm having serious issues with the li...   \n",
       "\n",
       "                                           Utterance  \\\n",
       "0                  PriceChild: thanks a lot! __eou__   \n",
       "1                             you're welcome __eou__   \n",
       "2  Right.  You'll need to run your live-cd and go...   \n",
       "3                  I'm not in the directory! __eou__   \n",
       "\n",
       "                                           statement  \\\n",
       "0                 install the pidgin-otr package \\n    \n",
       "1                                         thanks \\n    \n",
       "2   : That would be very nice due to the fact tha...   \n",
       "3   : or cd out of devices the directory... that ...   \n",
       "\n",
       "                                               reply  \n",
       "0                       PriceChild: thanks a lot! \\n  \n",
       "1                                  you're welcome \\n  \n",
       "2  Right.  You'll need to run your live-cd and go...  \n",
       "3                       I'm not in the directory! \\n  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(n=14000, random_state=42)\n",
    "df_sample.reset_index(inplace=True)\n",
    "df_sample.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f89fa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.3, max_features=500, min_df=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.3, max_features=500, min_df=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.3, max_features=500, min_df=8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf = TfidfVectorizer(min_df=8, max_df=.3, max_features=50000)\n",
    "tfidf = TfidfVectorizer(min_df=8, max_df=.3, max_features=500)\n",
    "# tfidf.fit(df.statement)  # <1>\n",
    "tfidf.fit(df_sample.statement)  # <1>\n",
    "\n",
    "# <1> Notice you only need to compute the statement (not reply) TF-IDFs, because those are the\n",
    "#     things you want to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758e5646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# X = tfidf.transform(df.statement)\n",
    "X = tfidf.transform(df_sample.statement)\n",
    "X = pd.DataFrame(X.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d3e0c16-2181-460b-90da-df5ac21e2ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ff2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf.transform(['This is an example statement that\\\n",
    "    we want to retrive the best reply for.'])\n",
    "\n",
    "cosine_similarities = x.dot(X.T)\n",
    "# reply = df.loc[cosine_similarities.argmax()]\n",
    "reply = df_sample.loc[cosine_similarities.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d20a4c8d-7a5d-4e6d-a90e-2241a5f2881e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                   429085\n",
       "Context      some one here that can help me merg two small ...\n",
       "Utterance                            thanx for that :) __eou__\n",
       "statement      #friendly-coders is the best place for that \\n \n",
       "reply                                     thanx for that :) \\n\n",
       "Name: 6972, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0c74900ca11cd9a4678e4c10a950358c13d37493068129285070960ce9781b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
